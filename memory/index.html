<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="Compressed Memory">
  <meta name="keywords" content="Context compression">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Compressed Context Memory for Online Language Model Interaction
  </title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" type="image/png" href="images/icon.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Compressed Context Memory for<br /> Online Language Model
              Interaction
            </h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://janghyun1230.github.io/">Jang-Hyun Kim</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="https://yeomjy.com/">Junyoung Yeom</a><sup>2</sup>,</span>
              <span class="author-block">
                <a href="https://sangdooyun.github.io/">Sangdoo Yun</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="https://mllab.snu.ac.kr/hyunoh/">Hyun Oh Song</a><sup>2</sup>,
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>Seoul National University,</span>
              <span class="author-block"><sup>2</sup>NAVER AI Lab</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="./static/ccm24.pdf" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2011.12948" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/snu-mllab/Context-Memory"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
              </div>

            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <img src="./static/images/main.png">
        <h2 class="subtitle has-text-centered">
          <span class="dnerf">Our approach compresses accumulating contexts into a compact memory space,<br /> reducing
            memory
            requirement during inference and enhancing computational efficiecy.</span>
        </h2>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              This paper presents a novel context compression method for Transformer language models in online scenarios
              such as ChatGPT, where the context continually expands.
              As the context lengthens, the attention process requires more memory and computational resources, which in
              turn reduces the throughput of the language model.
              To this end, we propose a compressed context memory system that continually compresses the growing context
              into a compact memory space.
              The compression process simply involves integrating a lightweight conditional LoRA into the language
              model's forward pass during inference.
              Based on the compressed context memory, the language model can perform inference with reduced memory and
              attention operations.
              Through evaluations on conversation, personalization, and multi-task learning, we demonstrate that our
              approach achieves the performance level of a full context model with 5x smaller context memory
              space.
            </p>
          </div>
        </div>
      </div>
      <!--/ Abstract. -->
      <br>
      <!-- Paper video. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Results</h2>
          <div class="publication-image">
            <img src="./static/images/result.png">
          </div>
          <br>
          <br>
          <div class="publication-image">
            <img src="./static/images/example.png">
          </div>
          <br>
          <br>
          <div class="publication-image">
            <img src="./static/images/throughput.png">
          </div>
        </div>
      </div>
      <!--/ Paper video. -->
    </div>
  </section>


  <section class="section">
    <!-- Concurrent Work. -->
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column is-four-fifths">
          <div class="content">
            <h2 class="title is-3">Related Links</h2>

            <div class="content has-text-justified">
              <p>
                There's a lot of excellent work that was introduced around the same time as ours.
              </p>
              <p>
                <a href="https://arxiv.org/abs/2104.09125">Progressive Encoding for Neural Optimization</a> introduces
                an
                idea similar to our windowed position encoding for coarse-to-fine optimization.
              </p>
              <p>
                <a href="https://www.albertpumarola.com/research/D-NeRF/index.html">D-NeRF</a> and <a
                  href="https://gvv.mpi-inf.mpg.de/projects/nonrigid_nerf/">NR-NeRF</a>
                both use deformation fields to model non-rigid scenes.
              </p>
              <p>
                Some works model videos with a NeRF by directly modulating the density, such as <a
                  href="https://video-nerf.github.io/">Video-NeRF</a>, <a
                  href="https://www.cs.cornell.edu/~zl548/NSFF/">NSFF</a>, and <a
                  href="https://neural-3d-video.github.io/">DyNeRF</a>
              </p>
              <p>
                There are probably many more by the time you are reading this. Check out <a
                  href="https://dellaert.github.io/NeRF/">Frank Dellart's survey on recent NeRF papers</a>, and <a
                  href="https://github.com/yenchenlin/awesome-NeRF">Yen-Chen Lin's curated list of NeRF papers</a>.
              </p>
            </div>
          </div>
          <h2 class="title">BibTeX</h2>
          <pre><code>@article{kim23memory,
    author = {Kim, Jang-Hyun and Yeom, Junyoung and Yun, Sangdoo and Song, Hyun Oh},
    title = {Compressed Context Memory for Online Language Model Interaction},
    journal = {arxiv},
    year = {2023}}</code></pre>
        </div>
      </div>
    </div>
  </section>

  <footer class="footer">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
              href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
              Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            Website adapted from the following <a href="https://github.com/nerfies/nerfies.github.io">source code</a>.
          </p>
        </div>
      </div>
    </div>
    </div>
  </footer>


</body>

</html>