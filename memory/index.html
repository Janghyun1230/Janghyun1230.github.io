<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="Compressed Context Memory for Online Language Model Interaction">
  <meta name="keywords" content="Context compression">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Compressed Context Memory for Online Language Model Interaction
  </title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Compressed Context Memory for<br /> Online Language Model
              Interaction
            </h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://janghyun1230.github.io/">Jang-Hyun Kim</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="https://yeomjy.com/">Junyoung Yeom</a><sup>2</sup>,</span>
              <span class="author-block">
                <a href="https://sangdooyun.github.io/">Sangdoo Yun</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="https://mllab.snu.ac.kr/hyunoh/">Hyun Oh Song</a><sup>2</sup>,
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>Seoul National University,</span>
              <span class="author-block"><sup>2</sup>NAVER AI Lab</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2011.12948" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2011.12948" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/google/nerfies" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
              </div>

            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <video id="teaser" autoplay muted loop playsinline height="100%">
          <source src="./static/videos/teaser.mp4" type="video/mp4">
        </video>
        <h2 class="subtitle has-text-centered">
          <span class="dnerf">Nerfies</span> turns selfie videos from your phone into
          free-viewpoint
          portraits.
        </h2>
      </div>
    </div>
  </section>


  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              This paper presents a novel context compression method for Transformer language models in online scenarios
              such as ChatGPT, where the context continually expands.
              As the context lengthens, the attention process requires more memory and computational resources, which in
              turn reduces the throughput of the language model.
              To this end, we propose a compressed context memory system that continually compresses the growing context
              into a compact memory space.
              The compression process simply involves integrating a lightweight conditional LoRA into the language
              model's forward pass during inference.
              Based on the compressed context memory, the language model can perform inference with reduced memory and
              attention operations.
              Through evaluations on multi-task learning, personalization, and conversation, we demonstrate that our
              approach achieves the performance level of a full context model with $5\times$ smaller context memory
              space.
            </p>
          </div>
        </div>
      </div>
      <!--/ Abstract. -->

      <!-- Paper video. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Video</h2>
          <div class="publication-video">
            <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0" frameborder="0"
              allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
      <!--/ Paper video. -->
    </div>
  </section>


  <section class="section">
    <div class="container is-max-desktop">

      <div class="columns is-centered">

        <!-- Visual Effects. -->
        <div class="column">
          <div class="content">
            <h2 class="title is-3">Visual Effects</h2>
            <p>
              Using <i>nerfies</i> you can create fun visual effects. This Dolly zoom effect
              would be impossible without nerfies since it would require going through a wall.
            </p>
            <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/dollyzoom-stacked.mp4" type="video/mp4">
            </video>
          </div>
        </div>
        <!--/ Visual Effects. -->

      </div>
    </div>
    <!--/ Animation. -->


    <!-- Concurrent Work. -->
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column">
          <div class="content">
            <h2 class="title is-3">Related Links</h2>

            <div class="content has-text-justified">
              <p>
                There's a lot of excellent work that was introduced around the same time as ours.
              </p>
              <p>
                <a href="https://arxiv.org/abs/2104.09125">Progressive Encoding for Neural Optimization</a> introduces
                an
                idea similar to our windowed position encoding for coarse-to-fine optimization.
              </p>
              <p>
                <a href="https://www.albertpumarola.com/research/D-NeRF/index.html">D-NeRF</a> and <a
                  href="https://gvv.mpi-inf.mpg.de/projects/nonrigid_nerf/">NR-NeRF</a>
                both use deformation fields to model non-rigid scenes.
              </p>
              <p>
                Some works model videos with a NeRF by directly modulating the density, such as <a
                  href="https://video-nerf.github.io/">Video-NeRF</a>, <a
                  href="https://www.cs.cornell.edu/~zl548/NSFF/">NSFF</a>, and <a
                  href="https://neural-3d-video.github.io/">DyNeRF</a>
              </p>
              <p>
                There are probably many more by the time you are reading this. Check out <a
                  href="https://dellaert.github.io/NeRF/">Frank Dellart's survey on recent NeRF papers</a>, and <a
                  href="https://github.com/yenchenlin/awesome-NeRF">Yen-Chen Lin's curated list of NeRF papers</a>.
              </p>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{kim23memory,
  author    = {Kim, Jang-Hyun and Yeom, Junyoung and Yun, Sangdoo and Song, Hyun Oh},
  title     = {Compressed Context Memory for Online Language Model Interaction},
  journal   = {arxiv},
  year      = {2023},
}</code></pre>
    </div>
  </section>


  <footer class="footer">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
              href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
              Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            Website adapted from the following <a href="https://github.com/nerfies/nerfies.github.io">source code</a>.
          </p>
        </div>
      </div>
    </div>
    </div>
  </footer>


</body>

</html>